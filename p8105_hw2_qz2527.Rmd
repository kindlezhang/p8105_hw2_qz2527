---
title: "p8105_hw2_qz2527.Rmd"
author: "kindle zhang"
date: "2023-10-01"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
```

## Problem 1

First, clean the data in `pols-month.csv`. Use `separate()` to break up the variable
`mon` into integer variables `year`, `month`, and `day`; replace month number with month
name; create a `president` variable taking values `gop` and `dem`, and remove `prez_dem`
and `prez_gop`; and remove the day variable.

```{r}

month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

my_data_1 = read.csv("data_file/pols-month.csv") |> 
  janitor::clean_names() |> 
  separate(mon, into = c("year", "month", "day"), "-") |> 
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day)) |> 
  mutate(
    month = case_match(
        month,
        01 ~ "January",
        02 ~ "February",
        03 ~ "March",
        04 ~ "April",
        05 ~ "May",
        06 ~ "June",
        07 ~ "July",
        08 ~ "August",
        09 ~ "September",
        10 ~ "October",
        11 ~ "November",
        12 ~ "December",
      )
  ) |> 
  mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

Second, clean the data in `snp.csv` using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that `year` and `month` are the leading columns.

```{r clean data}
my_data_2 = 
  read_csv(
    "data_file/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |> 
  janitor::clean_names() |> 
  separate(date, into = c("year","month_num", "day"), convert = TRUE) |> 
  mutate(year = if_else(year>2023, year-100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close)
  
```
Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
my_data_3 = 
  read_csv("./data_file/unemployment.csv") |> 
  rename(year = Year)|> 
  pivot_longer(
    Jan:Dec,
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```
Join the datasets by merging `snp` into `pols`, and merging `unemployment` into the result.

```{r}
data_new = 
  left_join(my_data_1, my_data_2) |> 
  left_join(x = _, y = my_data_3)
  
str(data_new)
```
Let's talk about the 538 data_new. The `my_data_1` data has `r nrow(my_data_1)` observations and `r ncol(my_data_1)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r my_data_1 |> pull(year) |> min()` to `r my_data_2 |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `my_data_2` data has `r nrow(my_data_2)` observations and `r ncol(my_data_2)` variables, ranging from years `r my_data_2 |> pull(year) |> min()` to `r my_data_2 |> pull(year) |> max()`. The `my_data_3` data has `r nrow(my_data_3)` observations and `r ncol(my_data_3)` variables ranging from years `r my_data_3 |> pull(year) |> min()` to `r my_data_3 |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_new, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_new, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.

## Problem 2

Read and clean the Mr. Trash Wheel sheet:
* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel`
* use reasonable variable names
* omit rows that do not include dumpster-specific data

```{r, incluse = FALSE}
library(readxl)
```

```{r}
data_tw = 
  read_excel("./data_file/202309_tw.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:M586") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    year = as.numeric(year)
  )
```
The data include a column for the (approximate) number of homes powered. This calculation is described in the `Homes powered note`, but not applied to every row in the dataset. Update the data to include a new `homes_powered` variable based on this calculation.

```{r}
data_tw = 
mutate(
  data_tw,
  homes_powered = (weight_tons * 500) / 30
  )
```
Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset. To keep track of which Trash Wheel is which, you may need to add an additional variable to all datasets before combining.

```{r}
data_ptw = 
  read_excel("./data_file/202309_tw.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:L108") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(homes_powered = (weight_tons * 500) / 30)

data_gtw = 
  read_excel("./data_file/202309_tw.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:K157") |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(homes_powered = (weight_tons * 500) / 30)
```
```{r}
data_tw = 
  mutate(
    data_tw,
    trash_wheel_kind = "Mr. Trash Wheel"
  )

data_ptw = 
  mutate(
    data_ptw,
    trash_wheel_kind = "Professor Trash Wheel"
  )

data_gtw = 
  mutate(
    data_gtw,
    trash_wheel_kind = "Gwynnda Trash Wheel"
  )
data_tw_all = 
  bind_rows(data_tw, data_ptw, data_gtw)

str(data_tw_all)
```
Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in July of 2021?

Let's talk about the data_tw_all. The `data_tw` data has `r nrow(data_tw)` observations and `r ncol(data_tw)` variables and tells us about the  information on the dumpter number, date of collection, amount of total litter and litter type for a given year from years `r data_tw |> pull(year) |> min()` to `r data_tw |> pull(year) |> max()`. It also tells us the homes powered. The `data_ptw` data has `r nrow(data_ptw)` observations and `r ncol(data_ptw)` variables, ranging from years `r data_ptw |> pull(year) |> min()` to `r data_ptw |> pull(year) |> max()`. The `data_gtw` data has `r nrow(data_gtw)` observations and `r ncol(data_gtw)` variables ranging from years `r data_gtw |> pull(year) |> min()` to `r data_gtw |> pull(year) |> max()`. 

The total weight of trash collected by Professor Trash Wheel is `r filter(data_tw_all, trash_wheel_kind == "Professor Trash Wheel") |> pull(weight_tons) |> sum()` tons. The total number of cigarette butts collected by Gwynnda in July of 2021 is `r filter(data_tw_all, trash_wheel_kind == "Gwynnda Trash Wheel" & year == 2021 & month == "July") |> pull(cigarette_butts) |> sum(digit = 0)`

## Problem 3

Import, clean, and tidy the dataset of baseline demographics.

```{r}
data_mb = 
  read_csv("./data_file/MCI_baseline.csv", skip = 1)|> 
  janitor::clean_names()
```
Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).

```{r}
data_mb_new = 
  mutate(
    data_mb,
    sex = recode(sex, "1" = "male", "0" = "female")
  ) |> 
  mutate(
    apoe4 = recode(apoe4, "1" = "carrier", "0" = "non-carrier")
  ) |> 
  filter(age_at_onset == ".")
```

* In the importing process, we should skip the first line cause it's the explanatory note to the variable.
* We should transmit the `sex` and `apoe4` to a character.
* We should delete the participants who are not qualified because of getting a MIC in the baseline time.

### some conclusions:

* the recruits' number is `r nrow(data_mb)`, among which `r nrow(data_mb) - nrow(data_mb_new)` ones got a MCI.
* the average baseline age is `r data_mb_new |> pull(current_age) |> mean() |> round(digit = 2)` years old.
* the proportion of women in the study who are APOE4 carriers is `r filter(data_mb_new, sex == "female" & apoe4 == "carrier")|> nrow()/nrow(data_mb_new)` 

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values.

```{r}
data_am = 
  read_csv("./data_file/mci_amyloid.csv", skip = 1,
           col_types = "iddddd")|> 
  janitor::clean_names() |> 
  rename(id = study_id) |> 
  drop_na()
```

the form `data_am` records the `r nrow(data_am)` individuals' data about their amyloid β 42/40 ratio in a specific period. 

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory

```{r}
data_final =
  left_join(data_mb_new, data_am, by = "id")

data_final_2 = 
  drop_na(data_final) |> 
  write.table("./data_file/data_final.csv", row.names = FALSE, col.names = TRUE, sep = ",")
```
There are some participants appear in only the baseline or amyloid datasets. There're `r nrow(data_final_2)` individuals retain in the final form.
